name: lang_ident_classifier
channels:
  - defaults
  - conda-forge
  - pytorch
  - nvidia
dependencies:
  - python=3.10
  - pytorch=2.3.0
  - cudatoolkit=12.1  # Ensure this matches your GPU and FlashAttention needs
  - pip
  - pip:
      - filelock==3.16.1
      - huggingface_hub==0.27.1
      - ipywidgets==8.1.7
      - langcodes==3.4.0
      - lightning==2.1.4
      - numpy==1.23.0
      - optuna==3.6.1
      - optuna-distributed==0.7.0
      - optuna-integration==4.3.0
      - pandarallel==1.6.5
      - pandas==2.0.3
      - pathos==0.3.4
      - peft==0.4.0
      - prettytable==3.16.0
      - psutil==7.0.0
      - py_cpuinfo==9.0.0
      - pyparsing==3.2.3
      - PyYAML==6.0.2
      - quanto==0.2.0
      - nvidia-ml-py3==7.352.0
      - rapidfuzz==3.13.0
      - sentencepiece==0.2.0
      - scikit_learn==1.6.1
      - torchmetrics==1.2.1
      - transformers==4.48.0
      - bitsandbytes==0.45.5
      - cachetools==5.5.2
      - xformers==0.0.23.post1
      # FlashAttention must be compiled; requires nvcc from CUDA Toolkit â‰¥11.7
      # Uncomment below after verifying CUDA setup (optional):
      # - flash-attn==2.8.2

