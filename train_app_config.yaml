app:
  model_config_name: "lang_ident_classifier_optim_test"
  data_dir: "data"
  logs_dir: "logs"
  pretrained_embeddings_dir: "pretrained_embeddings"
  checkpoints_dir: "checkpoints"
  random_seed: 20
  num_trials: 500
run_config:
  accumulate_grad_batches: 2
  training_precision_type: "16-mixed"
  data_sample_share: 1.0
  pretrained_embedding_names: "ai4bharat/IndicBERTv2-MLM-only"
  pretrained_embedding_overwrite_old: False
  max_seq_len: 500
  batch_size: 4
  optimizer: "adamw"
  num_backbone_model_units_unfrozen: 4
  loss_type: "class_weighted_focal_loss_with_adaptive_focus_type1"
  learning_rate: 0.001
  num_fc_layers_in_classifier_head: 2
logs:
  prefix: "%Y%m%d"
  suffix: "lang_ident_classifier_app.log"
  message_format: "[%(asctime)s GMT] %(levelname)s::%(funcName)s() %(message)s"
dataset:
  train_dataset_sample_share: 0.01
  val_dataset_sample_share: 0.01
  files_have_header: True
  train:
    data_dir: "train"
  val:
    data_dir: "val"
  test:
    data_dir: "test"
model:
  finetune_status: False
  max_epochs: 3

